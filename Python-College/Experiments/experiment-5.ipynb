{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a function to extract all unique words from a text while ignoring case and\n",
    "punctuation and return the result as a sorted list.\n",
    "Input: \"Hello world! Welcome to the world of Data Science.\" Expected Output: ['data',\n",
    "'hello', 'of', 'science', 'the', 'to','welcome', 'world']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'hello', 'of', 'science', 'the', 'to', 'welcome', 'world']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_unique_words(text):\n",
    "    text = text.lower()\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    unique_words = sorted(set(words))\n",
    "    return unique_words\n",
    "input_text = \"Hello world! Welcome to the world of Data Science.\"\n",
    "print(extract_unique_words(input_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a function to identify and count the number of distinct named entities (e.g.,\n",
    "names of people, places, organizations) using regular expressions in a text.\n",
    "Input: \"Barack Obama was born in Hawaii. Google is a major techcompany.\"\n",
    "Expected Output: {'Barack Obama': 1, 'Hawaii': 1, 'Google': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Barack Obama': 1, 'Hawaii': 1, 'Google': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"Barack Obama was born in Hawaii. Google is a major tech company.\"\n",
    "pattern = r\"[A-Z][a-z]+\\s[A-Z][a-z]+|[A-Z][a-z]+\"\n",
    "s2 = re.findall(pattern,s)\n",
    "freq = {}\n",
    "\n",
    "for s in s2:\n",
    "    if s in freq:\n",
    "        freq[s] += 1\n",
    "    else:\n",
    "        freq[s] = 1\n",
    "freq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a function to extract and normalize all dates from a text, converting them\n",
    "into a standard YYYY-MM-DDformat.\n",
    "Input: \"The event is scheduled for 12/31/2024 and the deadline is01-15-2024.\"\n",
    "Expected Output: ['2024-12-31', '2024-01-15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The event is scheduled for 2024-31-12 and the deadline is 2024-15-01.\n"
     ]
    }
   ],
   "source": [
    "datetext=\"The event is scheduled for 12/31/2024 and the deadline is 01-15-2024.\"\n",
    "def correctDateFormat(datetext):\n",
    "    p3=r\"([0-9]{2})\\-([0-9]{2})\\-([0-9]{4})\"\n",
    "    datetext=re.sub(r\"[\\/]\",\"-\",datetext)\n",
    "    # Use of grouping can be done using Ragex in order to match a given pattern and refa\n",
    "    dateList=re.sub(p3,r\"\\3-\\2-\\1\",datetext)\n",
    "    return dateList\n",
    "print(correctDateFormat(datetext))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write a function to identify and extract key-value pairs from a structured textformat\n",
    "(e.g., \"key1: value1; key2: value2\") and return them as a dictionary.\n",
    "Input: \"name: John Doe; age: 30; profession: Data Scientist\" Expected Output: {'name':\n",
    "'John Doe', 'age': '30', 'profession':'Data Scientist'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'John Doe', 'age': '30', 'profession': 'Data Scientist'}\n"
     ]
    }
   ],
   "source": [
    "def keyValuePair(data):\n",
    "    keysPattern=r\"[a-z]+[:]\"\n",
    "    valuePattern=r\"[A-Z]+[a-z]+\\s{1}[A-Z][a-z]+|[0-9]{1,}\"\n",
    "    keysList=re.findall(keysPattern,data)\n",
    "    valuesList=re.findall(valuePattern,data)\n",
    "    # Removing all the Semicolon Marks in KeysList using list comprehension\n",
    "    keysList=[x.replace(\":\",\"\") for x in keysList]\n",
    "    key_value=dict(zip(keysList,valuesList))\n",
    "    return key_value\n",
    "data=\"name: John Doe; age: 30; profession: Data Scientist\"\n",
    "print(keyValuePair(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Define a function to extract all phone numbers from a text and format them in the\n",
    "(XXX) XXX-XXXXpattern, regardless oftheir initialformat.\n",
    "Input: \"Contact me at 1234567890 or 987-654-3210.\"\n",
    "Expected Output: ['(123) 456-7890', '(987) 654-3210']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contact me at (123)456-7890 or (987)654-3210.\n"
     ]
    }
   ],
   "source": [
    "phoneData=\"Contact me at 1234567890 or 987-654-3210.\"\n",
    "def numberExtraction(phoneData):\n",
    "    p5=r\"([0-9]{3})([0-9]{3})([0-9]{4})\"\n",
    "    phoneData=re.sub(p5,r\"(\\1)\\2-\\3\",phoneData)\n",
    "    phoneData=re.sub(r\"([0-9]{3})\\-([0-9]{3})\\-([0-9]{4})\",r\"(\\1)\\2-\\3\",phoneData)\n",
    "    return phoneData\n",
    "print(numberExtraction(phoneData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Create a function that detects and extracts all currency amounts from a text and\n",
    "converts them to a standardized numeric format (e.g., \"$1,234.56\" to 1234.56).\n",
    "Input: \"The price is $1,234.56 and $789.00 for the additionalitems.\"\n",
    "Expected Output: [1234.56, 789.00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price is 1234.56 and 789.00 for the additional items\n"
     ]
    }
   ],
   "source": [
    "moneyText=\"The price is $1,234.56 and $789.00 for the additional items\"\n",
    "def moneyFormatter(moneyText):\n",
    "    moneyText=re.sub(r\"(\\$)([0-9]+)([\\.]+[0-9]+)\",r\"\\2\\3\",moneyText)\n",
    "    moneyText=re.sub(r\"(\\$)([0-9]{1,3})[\\,]([0-9]+)([\\.]+[0-9]+)\",r\"\\2\\3\\4\",moneyText)\n",
    "    return moneyText\n",
    "print(moneyFormatter(moneyText))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Write a function to identify and extract all instances of email addresses that are part of\n",
    "specific domains(e.g., @example.com) from a given text.\n",
    "Input: \"Please contact us at support@example.com orsales@otherdomain.com.\"\n",
    "Expected Output: ['support@example.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['support@example.com', 'sales@otherdomain.com']\n"
     ]
    }
   ],
   "source": [
    "emailText=\"Please contact us at support@example.com or sales@otherdomain.com.\"\n",
    "def emailExtracter(emailText):\n",
    "    emailList=re.findall(r\"[a-zA-Z0-9]+\\@[a-z]+\\.[a-z]{2,3}\",emailText)\n",
    "    return emailList\n",
    "print(emailExtracter(emailText))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Define a function that uses regular expressions to detect and extract complexpatterns\n",
    "such as ISBN numbers from a text, ensuring correct formatting.\n",
    "Input: \"The books have ISBN numbers like 978-3-16-148410-0 and 978-0-306-40615-\n",
    "7.\"\n",
    "Expected Output: ['978-3-16-148410-0', '978-0-306-40615-7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['978-3-16-148410-0', '978-0-306-40615-7']\n"
     ]
    }
   ],
   "source": [
    "isbnText=\"The books have ISBN numbers like 978-3-16-148410-0 and 978-0-306-40615-7.\"\n",
    "def isbnExtracter(isbnText):\n",
    "    isbnList=re.findall(r\"[0-9]{3}\\-[0-9]{1}\\-[0-9]{2,3}\\-[0-9]{5,6}\\-[0-9]{1}\",isbnText)\n",
    "    return isbnList\n",
    "print(isbnExtracter(isbnText))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Create a function to identify and extract URLs from a text while distinguishing\n",
    "between different types of URLs(e.g.,HTTP, HTTPS,FTP).\n",
    "Input: \"Visit our sites at http://example.com, https://secure-site.org, and\n",
    "ftp://files.example.net.\"\n",
    "Expected Output: ['http://example.com', 'https://secure-site.org','ftp://files.example.net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://example.com', 'https://secure-site.org', 'ftp://files.example.net']\n"
     ]
    }
   ],
   "source": [
    "urlText=\"Visit our sites at http://example.com, https://secure-site.org, and ftp://files.example.net\"\n",
    "def urlExtracter(urlText):\n",
    "    urlList=re.findall(r\"[a-z]+[\\:]//[a-z\\-]+(?:\\.[a-z]{2,})+\",urlText)\n",
    "    return urlList\n",
    "print(urlExtracter(urlText))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Write a function to clean and preprocess text by removing HTML tags, unnecessary\n",
    "whitespace, and converting special characters to their plain textequivalents.\n",
    "Input: \"Hello <b>World</b>! This is a <a\n",
    "href='http://example.com'>link</a>.\" Expected Output:\n",
    "\"Hello World! This is a link.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World! This is a link.\n"
     ]
    }
   ],
   "source": [
    "htmlData=\"Hello <b>World</b>! This is a <a href='http://example.com'>link</a>.\"\n",
    "def htmlDataCleaner(htmlData):\n",
    "    htmlData=re.sub(r\"<b>|</b>|<a|</a>| href='http://example.com'>\",\"\",htmlData)\n",
    "    return htmlData\n",
    "print(htmlDataCleaner(htmlData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Define a function to extract and sort all numerical values from a text, includinghandling\n",
    "numbers embedded in words or mixed with text.\n",
    "Input: \"The quantities are 12 apples, 2 oranges, and 25 bananas.\"\n",
    "Expected Output: [2, 12, 25]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 12, 25]\n"
     ]
    }
   ],
   "source": [
    "input = \"The quantities are 12 apples, 2 oranges, and 25 bananas.\"\n",
    "def sortextract(input):\n",
    "    ipdata = re.findall(r\"\\d+\", input)\n",
    "    ipdata = [int(x) for x in ipdata]\n",
    "    ipdata.sort()\n",
    "    return ipdata\n",
    "\n",
    "print(sortextract(input))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Create a function to identify and extract all instances of hashtags, mentions,and\n",
    "URLs from a social media post, ensuring proper separation and categorization.\n",
    "Input: \"Check out #DataScience and @JohnDoe's post athttp://example.com! #AI\"\n",
    "Expected Output: {'hashtags': ['#DataScience', '#AI'], 'mentions':['@JohnDoe'], 'urls':\n",
    "['http://example.com']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hastags': ['#DataScience', '#AI'], 'Tags': [\"@JohnDoe's\"], 'URLS': ['http://example.com']}\n"
     ]
    }
   ],
   "source": [
    "new_data=\"Check out #DataScience and @JohnDoe's post at http://example.com! #AI\"\n",
    "def dictdetailsExtracter(new_data):\n",
    "    hastags=re.findall(r\"\\#[\\w]+\",new_data)\n",
    "    tags=re.findall(r\"@[\\w\\']+\",new_data)\n",
    "    urls=re.findall(r\"[a-z]+[\\:]//[a-z\\-]+\\.[a-z]{2,3}\",new_data)\n",
    "    details=dict(zip(['Hastags','Tags','URLS'],[hastags,tags,urls]))\n",
    "    return details\n",
    "print(dictdetailsExtracter(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
