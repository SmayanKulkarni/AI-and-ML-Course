{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 12:05:08.026098: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-28 12:05:08.100201: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-28 12:05:08.174975: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-28 12:05:08.237696: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-28 12:05:08.255370: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-28 12:05:08.372706: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-28 12:05:09.610628: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the training data\n",
    "data = pd.read_csv('/home/smayan/Desktop/train.csv')\n",
    "\n",
    "# Mapping the target statuses\n",
    "status_mapping = {\n",
    "    'Approved': 1, 'Phase 2': 2, 'Phase 1': 3, 'Phase 3': 4,\n",
    "    'Investigative': 5, 'Phase 1/2': 6, 'Discontinued in Phase 2': 7,\n",
    "    'Terminated': 8, 'Patented': 9, 'Discontinued in Phase 3': 10,\n",
    "    'Discontinued in Phase 1': 11, 'Preclinical': 12, 'Withdrawn from market': 13,\n",
    "    'Phase 2/3': 14, 'Phase 4': 15, 'Clinical trial': 16,\n",
    "    'Preregistration': 17, 'Phase 1b': 18, 'Phase 2a': 19,\n",
    "    'Discontinued in Preregistration': 20, 'Discontinued in Phase 1/2': 21,\n",
    "    'Registered': 22, 'Approved (orphan drug)': 23, 'Application submitted': 24,\n",
    "    'IND submitted': 25, 'Discontinued in Phase 2/3': 26, 'Phase 2b': 27,\n",
    "    'Phase 0': 28, 'Discontinued in Phase 4': 29, 'BLA submitted': 30,\n",
    "    'Phase 1/2a': 31, 'Discontinued in Phase 2b': 32, 'Phase 1b/2a': 33\n",
    "}\n",
    "\n",
    "# Map target status\n",
    "data['Target_Status'] = data['Target_Status'].map(status_mapping)\n",
    "\n",
    "# Prepare features and labels\n",
    "X = data.drop(columns=['ID', 'Target_Status', 'TargetID', 'DRUGID', 'DRUGNAME', 'SEQUENCE', 'Accession Number'])\n",
    "y_encoded = data['Target_Status']\n",
    "\n",
    "# Feature engineering\n",
    "X['DrugType_HighStatus'] = X['DRUGTYPE'].astype(str) + '_' + X['Drug_high_status'].astype(str)\n",
    "X['DiseaseStatus_DrugStatus'] = X['Disease_of_highest_status'].astype(str) + '_' + X['Drug_Status'].astype(str)\n",
    "X['Unique_TargetID'] = X['UNIPROID'].astype(str) + '_' + X['TARGNAME'].astype(str) + '_' + X['GENENAME'].astype(str)\n",
    "X['BioClass_Function'] = X['BIOCLASS'].astype(str) + '_' + X['FUNCTION'].astype(str)\n",
    "\n",
    "# Drop original categorical columns\n",
    "X = X.drop(columns=['DRUGTYPE', 'Drug_high_status', 'Disease_of_highest_status', 'Drug_Status', 'UNIPROID', 'TARGNAME', 'GENENAME', 'BIOCLASS', 'FUNCTION'])\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "# Define the neural network model\n",
    "def create_nn_model(input_dim):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dense(len(status_mapping), activation='softmax')  # Number of classes for your target variable\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train the neural network\n",
    "input_dim = X_train.shape[1]\n",
    "nn_model = create_nn_model(input_dim)\n",
    "nn_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1)\n",
    "\n",
    "# Load and preprocess the test data\n",
    "test_df = pd.read_csv('/home/smayan/Desktop/test.csv')\n",
    "test_df['DrugType_HighStatus'] = test_df['DRUGTYPE'].astype(str) + '_' + test_df['Drug_high_status'].astype(str)\n",
    "test_df['DiseaseStatus_DrugStatus'] = test_df['Disease_of_highest_status'].astype(str) + '_' + test_df['Drug_Status'].astype(str)\n",
    "test_df['Unique_TargetID'] = test_df['UNIPROID'].astype(str) + '_' + test_df['TARGNAME'].astype(str) + '_' + test_df['GENENAME'].astype(str)\n",
    "test_df['BioClass_Function'] = test_df['BIOCLASS'].astype(str) + '_' + test_df['FUNCTION'].astype(str)\n",
    "\n",
    "# Drop original categorical columns\n",
    "test_df_processed = test_df.drop(columns=['DRUGTYPE', 'Drug_high_status', 'Disease_of_highest_status', 'Drug_Status', 'UNIPROID', 'TARGNAME', 'GENENAME', 'BIOCLASS', 'FUNCTION'])\n",
    "\n",
    "# One-hot encoding for test data\n",
    "test_df_processed = pd.get_dummies(test_df_processed)\n",
    "\n",
    "# Align test data columns with training data\n",
    "test_df_processed = test_df_processed.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = nn_model.predict(test_df_processed.to_numpy())\n",
    "test_predictions = np.argmax(test_predictions, axis=1)  # Get the predicted class labels\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_df['ID'],  \n",
    "    'Prediction': test_predictions\n",
    "})\n",
    "\n",
    "# Reverse the status mapping\n",
    "reverse_status_mapping = {v: k for k, v in status_mapping.items()}\n",
    "submission['Prediction'] = submission['Prediction'].map(reverse_status_mapping)\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission.to_csv('submission_nn.csv', index=False)\n",
    "\n",
    "print(\"Submission file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
