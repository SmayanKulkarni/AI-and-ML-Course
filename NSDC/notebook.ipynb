{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/home/smayan/Desktop/AI-ML-DS/NSDC/train.csv')\n",
    "test_df = pd.read_csv('/home/smayan/Desktop/AI-ML-DS/NSDC/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if pd.isna(text) or text == '':\n",
    "        return ''\n",
    "    if isinstance(text, (list, np.ndarray)):\n",
    "        text = ' '.join(map(str, text))\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', str(text).lower())\n",
    "    return ' '.join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = ['DRUGNAME', 'Disease_of_highest_status', 'TARGNAME', 'GENENAME', 'SYNONYMS', 'FUNCTION', 'BIOCLASS', 'Disease']\n",
    "for col in text_columns:\n",
    "    train_df[col] = train_df[col].apply(preprocess_text)\n",
    "    test_df[col] = test_df[col].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['combined_text'] = train_df[text_columns].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "test_df['combined_text'] = test_df[text_columns].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['PUBCHCID']\n",
    "categorical_columns = ['DRUGTYPE', 'Drug_high_status', 'Drug_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[numeric_columns + categorical_columns + ['combined_text']].copy()\n",
    "y = train_df['Target_Status']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_target = LabelEncoder()\n",
    "y_encoded = le_target.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_columns:\n",
    "    X.loc[:, col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numeric_columns),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns),\n",
    "        ('text', TfidfVectorizer(max_features=1000), 'combined_text')\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(random_state=42, n_jobs=-1))  \n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [3, 5],\n",
    "    'classifier__learning_rate': [0.01, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='f1_weighted', n_jobs=-1, error_score='raise')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_val)\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "print(f\"Validation F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X, y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df[numeric_columns + categorical_columns + ['combined_text']].copy()\n",
    "\n",
    "for col in numeric_columns:\n",
    "    X_test.loc[:, col] = pd.to_numeric(X_test[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_predictions_encoded = best_model.predict(X_test)\n",
    "\n",
    "test_predictions = le_target.inverse_transform(test_predictions_encoded)\n",
    "\n",
    "submission = pd.DataFrame({'ID': test_df['ID'], 'Prediction': test_predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
